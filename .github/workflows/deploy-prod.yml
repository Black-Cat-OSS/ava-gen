name: Production Deploy Pipeline

on:
  # PR в main (develop → main) - полное тестирование БЕЗ деплоя
  pull_request:
    branches:
      - main
    types: [opened, synchronize, reopened]

  # Push в main (после мерджа) - полное тестирование + ДЕПЛОЙ
  push:
    branches:
      - main

  # Ручной запуск для экстренных случаев
  workflow_dispatch:
    inputs:
      skip_tests:
        description: 'Skip tests (use only for hotfixes)'
        required: false
        default: false
        type: boolean
      skip_integration:
        description: 'Skip integration tests'
        required: false
        default: false
        type: boolean
      force_deploy:
        description: 'Force deploy (even on PR)'
        required: false
        default: false
        type: boolean

permissions:
  contents: read
  issues: write
  pull-requests: read

env:
  NODE_VERSION: '20'
  PNPM_VERSION: '10'

jobs:
  # ========================================
  # Stage 1: Unit & E2E Tests
  # ========================================
  # Примечание: Линтинг пропущен, т.к. код уже прошел проверку
  # в CI workflow при PR в develop
  #
  # Этот workflow запускается для:
  # - PR в main: полное тестирование БЕЗ деплоя
  # - Push в main: полное тестирование + ДЕПЛОЙ
  test-backend:
    name: Test Backend (${{ matrix.test_name }})
    runs-on: ubuntu-latest
    if: github.event.inputs.skip_tests != 'true'
    strategy:
      fail-fast: false
      matrix:
        # Полная матрица тестов для продакшен деплоя
        database: [sqlite, postgresql]
        storage: [local, s3]
        include:
          - database: sqlite
            storage: local
            test_name: 'SQLite + Local'
          - database: sqlite
            storage: s3
            test_name: 'SQLite + S3'
          - database: postgresql
            storage: local
            test_name: 'PostgreSQL + Local'
          - database: postgresql
            storage: s3
            test_name: 'PostgreSQL + S3'
    defaults:
      run:
        working-directory: backend

    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: password
          POSTGRES_DB: avatar_gen_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Wait for PostgreSQL
        if: matrix.database == 'postgresql'
        run: |
          for i in {1..30}; do
            if pg_isready -h localhost -p 5432 -U postgres; then
              echo "PostgreSQL is ready"
              exit 0
            fi
            echo "Waiting for PostgreSQL... ($i/30)"
            sleep 2
          done
          echo "PostgreSQL failed to start"
          exit 1

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Get pnpm store directory
        id: pnpm-cache
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT

      - name: Setup pnpm cache
        uses: actions/cache@v4
        with:
          path: ${{ steps.pnpm-cache.outputs.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Generate Prisma Client
        run: pnpm exec prisma generate

      - name: Create test configuration
        run: |
          # Создаем базовую конфигурацию
          cat > settings.test.matrix.yaml << EOF
          app:
            storage:
              type: '${{ matrix.storage }}'
              local:
                save_path: './storage/test-avatars'
              s3:
                endpoint: '${{ secrets.TEST_S3_ENDPOINT || 'https://test-s3-endpoint.com' }}'
                bucket: '${{ secrets.TEST_S3_BUCKET || 'avatar-gen-test' }}'
                access_key: '${{ secrets.TEST_S3_ACCESS_KEY || 'test-access-key' }}'
                secret_key: '${{ secrets.TEST_S3_SECRET_KEY || 'test-secret-key' }}'
                region: '${{ secrets.TEST_S3_REGION || 'us-east-1' }}'
                force_path_style: true
                connection:
                  maxRetries: 1
                  retryDelay: 100
            database:
              driver: '${{ matrix.database }}'
              connection:
                maxRetries: 1
                retryDelay: 100
              sqlite_params:
                url: 'file:./storage/test-database/database.test.sqlite'
              network:
                host: 'localhost'
                port: 5432
                database: 'avatar_gen_test'
                username: 'postgres'
                password: 'password'
                ssl: false
            logging:
              level: 'error'
              verbose: false
              pretty: false
          EOF

      - name: Run tests
        run: pnpm run test
        env:
          NODE_ENV: test
          TEST_MATRIX_CONFIG: ./settings.test.matrix.yaml

      - name: Run e2e tests
        run: pnpm run test:e2e
        env:
          NODE_ENV: test
          TEST_MATRIX_CONFIG: ./settings.test.matrix.yaml

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        if: always()
        with:
          files: ./backend/coverage/lcov.info
          flags: backend-${{ matrix.database }}-${{ matrix.storage }}
          name: backend-coverage-${{ matrix.database }}-${{ matrix.storage }}

  # ========================================
  # Stage 2: Build Frontend
  # ========================================
  build-frontend:
    name: Build Frontend
    runs-on: ubuntu-latest
    if: github.event.inputs.skip_tests != 'true'
    defaults:
      run:
        working-directory: frontend

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Get pnpm store directory
        id: pnpm-cache
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT

      - name: Setup pnpm cache
        uses: actions/cache@v4
        with:
          path: ${{ steps.pnpm-cache.outputs.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build
        run: pnpm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build
          path: frontend/dist
          retention-days: 1

  # ========================================
  # Stage 3: Docker Images Build (Parallel)
  # ========================================
  build-backend-image:
    name: Build Backend Image
    runs-on: ubuntu-latest
    needs: [test-backend]
    if: always() && (needs.test-backend.result == 'success' || needs.test-backend.result == 'skipped')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build backend image
        uses: docker/build-push-action@v6
        with:
          context: ./backend
          file: ./backend/docker/Dockerfile
          push: false
          tags: avatar-gen-backend:latest
          cache-from: type=gha,scope=backend
          cache-to: type=gha,mode=max,scope=backend

  build-frontend-image:
    name: Build Frontend Image
    runs-on: ubuntu-latest
    needs: [build-frontend]
    if: always() && (needs.build-frontend.result == 'success' || needs.build-frontend.result == 'skipped')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build frontend image
        uses: docker/build-push-action@v6
        with:
          context: ./frontend
          file: ./frontend/docker/Dockerfile
          push: false
          tags: avatar-gen-frontend:latest
          cache-from: type=gha,scope=frontend
          cache-to: type=gha,mode=max,scope=frontend

  build-gateway-image:
    name: Build Gateway Image
    runs-on: ubuntu-latest
    needs: [test-backend, build-frontend]
    if: always() && (needs.test-backend.result == 'success' || needs.test-backend.result == 'skipped') && (needs.build-frontend.result == 'success' || needs.build-frontend.result == 'skipped')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build gateway image
        uses: docker/build-push-action@v6
        with:
          context: ./gateway
          file: ./gateway/Dockerfile
          push: false
          tags: avatar-gen-gateway:latest
          cache-from: type=gha,scope=gateway
          cache-to: type=gha,mode=max,scope=gateway

  # ========================================
  # Stage 4: Integration Tests
  # ========================================
  integration-test:
    name: Integration Test (${{ matrix.test_name }})
    runs-on: ubuntu-latest
    needs: [build-backend-image, build-frontend-image, build-gateway-image]
    if: github.event.inputs.skip_integration != 'true'

    strategy:
      fail-fast: false
      matrix:
        database: [sqlite, postgresql]
        include:
          - database: sqlite
            test_name: 'SQLite'
            db_url: 'file:./storage/database/database.sqlite'
          - database: postgresql
            test_name: 'PostgreSQL'
            db_url: 'postgresql://postgres:password@postgres:5432/avatar_gen'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create external network
        run: docker network create avatar-gen-external

      - name: Prepare integration test environment (${{ matrix.test_name }})
        run: |
          echo "Preparing environment for ${{ matrix.test_name }} test..."

          # Создаем директории для storage
          mkdir -p backend/storage/database
          mkdir -p backend/storage/avatars

          # Создаем пустой файл БД для SQLite и устанавливаем права
          touch backend/storage/database/database.sqlite
          chmod -R 777 backend/storage

          # Создаем пустые .local.yaml файлы, чтобы Docker не создал их как директории
          touch backend/settings.local.yaml
          touch backend/settings.production.local.yaml

          # Создаем минимальный settings.yaml с поддержкой ENV переменных
          cat > backend/settings.yaml << 'EOF'
          app:
            storage:
              type: '${STORAGE_TYPE:-local}'
              local:
                save_path: './storage/avatars'
              s3:
                endpoint: '${S3_ENDPOINT:-http://localhost:9000}'
                bucket: '${S3_BUCKET:-avatars}'
                access_key: '${S3_ACCESS_KEY:-minioadmin}'
                secret_key: '${S3_SECRET_KEY:-minioadmin}'
                region: '${S3_REGION:-us-east-1}'
                force_path_style: true
                connection:
                  maxRetries: 3
                  retryDelay: 2000
            server:
              host: '0.0.0.0'
              port: 3000
            database:
              driver: '${DATABASE_PROVIDER:-sqlite}'
              connection:
                maxRetries: 3
                retryDelay: 2000
              sqlite_params:
                url: '${DATABASE_URL:-file:./storage/database/database.sqlite}'
              network:
                host: '${DB_HOST:-localhost}'
                port: 5432
                database: '${DB_NAME:-avatar_gen_test}'
                username: '${DB_USER:-postgres}'
                password: '${DB_PASSWORD:-password}'
                ssl: false
            logging:
              level: 'info'
              verbose: false
              pretty: true
          EOF

          echo "=== Created settings.yaml ==="
          cat backend/settings.yaml

          # Создаем docker-compose.override.yml для CI
          # КРИТИЧНО: Отключаем рестарты для тестов!
          cat > docker/docker-compose.override.yml << 'EOF'
          services:
            avatar-backend:
              restart: "no"
              volumes:
                - ../backend/storage:/app/storage
                - ../backend/logs:/app/logs
                - ../backend/settings.yaml:/app/settings.yaml:ro
            
            postgres:
              restart: "no"
            
            avatar-frontend:
              restart: "no"
            
            gateway:
              restart: "no"
          EOF

          echo "=== Docker Compose Override ==="
          cat docker/docker-compose.override.yml

          echo "=== Storage directory permissions ==="
          ls -la backend/storage/
          ls -la backend/storage/database/

      - name: Start services with Docker Compose (${{ matrix.test_name }})
        run: |
          # Создаём .env файл для docker-compose
          # КРИТИЧНО: export НЕ передаёт переменные в docker-compose!
          cat > docker/.env << EOF
          DATABASE_URL=${{ matrix.db_url }}
          DATABASE_PROVIDER=${{ matrix.database }}
          STORAGE_TYPE=local
          NODE_ENV=production
          EOF

          echo "=== Created docker/.env file ==="
          cat docker/.env
          echo "================================="

          # Запускаем сервисы
          # Для PostgreSQL используем профиль --profile postgresql
          if [ "${{ matrix.database }}" = "postgresql" ]; then
            echo "🐘 Starting services with PostgreSQL container..."
            docker compose --profile postgresql -f docker/docker-compose.yml up --build -d
          else
            echo "🗄️  Starting services with SQLite..."
            docker compose -f docker/docker-compose.yml up --build -d
          fi

          echo "Waiting for services to be ready..."
          sleep 45

      - name: Check container status
        run: |
          echo "=== Docker Compose Services (${{ matrix.test_name }}) ==="
          docker compose -f docker/docker-compose.yml ps

      - name: Show backend logs for debugging (${{ matrix.test_name }})
        if: always()
        run: |
          echo "=== Backend Container Logs (${{ matrix.test_name }}) ==="
          docker compose -f docker/docker-compose.yml logs avatar-backend
          echo "==========================================================="

          echo "=== Backend Container Environment ==="
          docker compose -f docker/docker-compose.yml exec -T avatar-backend env | grep -E "(DATABASE|STORAGE|NODE_ENV|CONFIG)" || echo "Container not running or exec failed"
          echo "======================================"

          echo "=== Generated Prisma Schema Check ==="
          docker compose -f docker/docker-compose.yml exec -T avatar-backend cat /app/prisma/schema.prisma | head -15 || echo "Cannot read schema"
          echo "======================================"

          if [ "${{ matrix.database }}" = "postgresql" ]; then
            echo "=== PostgreSQL Container Logs ==="
            docker compose -f docker/docker-compose.yml logs postgres
            echo "================================="
          fi

      - name: Check backend health
        run: |
          echo "Checking backend health endpoint..."
          for i in {1..10}; do
            if curl -f http://localhost:3000/api/health; then
              echo "Backend is healthy!"
              exit 0
            fi
            echo "Attempt $i failed, retrying..."
            sleep 5
          done
          echo "Backend health check failed after 10 attempts"
          docker compose -f docker/docker-compose.yml logs avatar-backend
          exit 1

      - name: Check frontend health
        run: |
          echo "Checking frontend health endpoint..."
          curl -f http://localhost:80/health || (docker compose -f docker/docker-compose.yml logs avatar-frontend && exit 1)

      - name: Check gateway
        run: |
          echo "Checking gateway..."
          curl -f http://localhost:80/ || (docker compose -f docker/docker-compose.yml logs gateway && exit 1)

      - name: Collect logs on failure
        if: failure()
        run: |
          echo "=== Collecting logs from containers ==="
          mkdir -p test-artifacts/logs
          mkdir -p test-artifacts/docker-logs

          # Сохраняем логи из всех контейнеров
          echo "Collecting docker compose logs..."
          docker compose -f docker/docker-compose.yml logs > test-artifacts/docker-logs/all-services.log 2>&1 || true
          docker compose -f docker/docker-compose.yml logs avatar-backend > test-artifacts/docker-logs/backend.log 2>&1 || true
          docker compose -f docker/docker-compose.yml logs avatar-frontend > test-artifacts/docker-logs/frontend.log 2>&1 || true
          docker compose -f docker/docker-compose.yml logs gateway > test-artifacts/docker-logs/gateway.log 2>&1 || true

          if [ "${{ matrix.database }}" = "postgresql" ]; then
            docker compose -f docker/docker-compose.yml logs postgres > test-artifacts/docker-logs/postgres.log 2>&1 || true
          fi

          # Копируем логи из volume (если есть)
          echo "Copying logs from backend volume..."
          docker compose -f docker/docker-compose.yml exec -T avatar-backend ls -la /app/logs 2>&1 | tee test-artifacts/logs/volume-listing.txt || true
          docker cp avatar-gen-backend:/app/logs test-artifacts/backend-app-logs 2>&1 || true

          # Копируем .env файл для диагностики
          cp docker/.env test-artifacts/docker-env-file.txt 2>&1 || true

          # Сохраняем статус контейнеров
          docker compose -f docker/docker-compose.yml ps > test-artifacts/container-status.txt 2>&1 || true
          docker ps -a > test-artifacts/docker-ps.txt 2>&1 || true

          # Сохраняем информацию о сети
          docker network ls > test-artifacts/networks.txt 2>&1 || true

          echo "=== Logs collected to test-artifacts/ ==="
          ls -la test-artifacts/

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-logs-${{ matrix.test_name }}-${{ github.run_id }}
          path: test-artifacts/
          retention-days: 7
          if-no-files-found: warn

      - name: Create GitHub Issue on failure
        if: failure() && github.event_name == 'push'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const testName = '${{ matrix.test_name }}';
            const database = '${{ matrix.database }}';
            const dbUrl = '${{ matrix.db_url }}';
            const branch = '${{ github.ref_name }}';
            const sha = '${{ github.sha }}';
            const runUrl = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';
            const commitUrl = '${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}';
            const actor = '${{ github.actor }}';
            const workflow = '${{ github.workflow }}';

            const body = `## Integration Test Failure Report

            **Test Variant:** ${testName}
            **Database:** ${database}
            **Branch:** \`${branch}\`
            **Commit:** ${sha}
            **Triggered by:** @${actor}

            ### Environment
            - **DATABASE_URL:** \`${dbUrl}\`
            - **DATABASE_PROVIDER:** \`${database}\`
            - **NODE_ENV:** \`production\`

            ### Quick Links
            - [Workflow Run](${runUrl})
            - [Commit](${commitUrl})

            ### Next Steps
            1. Check the workflow logs
            2. Review backend container logs in artifacts
            3. Verify Prisma schema generation
            4. Check database connectivity

            ---
            *Auto-created by GitHub Actions - Workflow: \`${workflow}\`*`;

            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `CI Failure: Integration Test ${testName}`,
              body: body,
              labels: ['ci-failure', 'integration-test', 'automated']
            });

            console.log(`Created issue #${issue.data.number}`);

      - name: Stop services
        if: always()
        run: docker compose -f docker/docker-compose.yml down --volumes

  # ========================================
  # Stage 5: Production Deployment
  # ========================================
  deploy:
    name: Deploy to Production Server
    runs-on: ubuntu-latest
    needs: [integration-test]
    # Деплой только при:
    # - push в main (после мерджа PR)
    # - ручной запуск с force_deploy=true
    # НЕ деплоим при PR в main (только тестируем)
    if: |
      always() &&
      (needs.integration-test.result == 'success' || needs.integration-test.result == 'skipped') &&
      (github.event_name == 'push' || github.event.inputs.force_deploy == 'true')
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -p ${{ secrets.SSH_PORT }} ${{ secrets.SSH_HOST }} >> ~/.ssh/known_hosts

      - name: Deploy to server
        env:
          SSH_HOST: ${{ secrets.SSH_HOST }}
          SSH_PORT: ${{ secrets.SSH_PORT }}
          SSH_USERNAME: ${{ secrets.SSH_USERNAME }}
          APP_PATH: ${{ secrets.APP_PATH }}
        run: |
          ssh -p $SSH_PORT $SSH_USERNAME@$SSH_HOST << 'ENDSSH'
            set -e
            cd ${{ secrets.APP_PATH }}
            
            echo "==================================="
            echo "  Production Deployment Started"
            echo "==================================="
            
            echo "📥 Pulling latest changes..."
            git fetch origin
            git reset --hard origin/main
            
            echo "🏗️  Building Docker images..."
            # Используем внешнюю PostgreSQL (без профиля postgresql)
            docker compose -f docker/docker-compose.yml build --no-cache
            
            echo "🛑 Stopping old containers..."
            docker compose -f docker/docker-compose.yml down
            
            echo "🚀 Starting new containers..."
            # Запуск с внешней PostgreSQL (DATABASE_URL должен быть в .env или secrets)
            docker compose -f docker/docker-compose.yml up -d
            
            echo "🧹 Cleaning up old images..."
            docker image prune -f
            
            echo "✅ Deployment completed successfully!"
          ENDSSH

      - name: Verify deployment
        env:
          SSH_HOST: ${{ secrets.SSH_HOST }}
          SSH_PORT: ${{ secrets.SSH_PORT }}
          SSH_USERNAME: ${{ secrets.SSH_USERNAME }}
          APP_PATH: ${{ secrets.APP_PATH }}
        run: |
          ssh -p $SSH_PORT $SSH_USERNAME@$SSH_HOST << 'ENDSSH'
            cd ${{ secrets.APP_PATH }}
            
            echo "Checking container status..."
            docker compose -f docker/docker-compose.yml ps
            
            echo "Checking backend health..."
            sleep 10
            curl -f http://localhost:3000/api/health || exit 1
            
            echo "All health checks passed!"
          ENDSSH

      - name: Cleanup SSH
        if: always()
        run: |
          rm -f ~/.ssh/id_rsa
